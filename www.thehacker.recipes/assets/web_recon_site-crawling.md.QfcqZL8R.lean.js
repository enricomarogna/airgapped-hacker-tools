import{_ as a,c as t,a5 as r,o as i}from"./chunks/framework.B5CpDqM0.js";const u=JSON.parse('{"title":"Site crawling","description":"","frontmatter":{"authors":"ShutdownRepo"},"headers":[],"relativePath":"web/recon/site-crawling.md","filePath":"web/recon/site-crawling.md","lastUpdated":1724982529000}'),s={name:"web/recon/site-crawling.md"};function n(o,e,h,l,c,p){return i(),t("div",null,e[0]||(e[0]=[r('<h1 id="site-crawling" tabindex="-1">Site crawling <a class="header-anchor" href="#site-crawling" aria-label="Permalink to &quot;Site crawling&quot;">​</a></h1><h2 id="theory" tabindex="-1">Theory <a class="header-anchor" href="#theory" aria-label="Permalink to &quot;Theory&quot;">​</a></h2><p>When requesting a web application, the server usually sends code (in HTML, CSS, Javascript, ...) in the response. This code is then rendered by the web browser. Each page contains links to other pages of the web app and resources needed by the browser to improve the render.</p><p>Crawling is a technique used to recursively follow those links and build the indexed website architecture. This architecture sometimes contains interesting links (admin log-in pages, API...) testers can focus on.</p><h2 id="practice" tabindex="-1">Practice <a class="header-anchor" href="#practice" aria-label="Permalink to &quot;Practice&quot;">​</a></h2><p>Tools like <a href="https://github.com/hakluke/hakrawler" target="_blank" rel="noreferrer">hakrawler</a> (Go), <a href="https://scrapy.org/" target="_blank" rel="noreferrer">scrapy</a> (Python) and <a href="https://github.com/rivermont/spidy" target="_blank" rel="noreferrer">spidy</a> (Python), and many other tools can be used for that purpose.</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">echo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $URL </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> hakrawler</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -d</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span></span></code></pre></div><p>Burp Suite&#39;s graphical interface is a great alternative (<code>Dashboard &gt; New scan (Crawl)</code> then <code>Target</code>).</p><p>Once the crawling is over, testers need to inspect the website architecture and look for admin paths, unusual redirections and anything that could lead to a potential vulnerability.</p>',9)]))}const g=a(s,[["render",n]]);export{u as __pageData,g as default};
